{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataclass to hold the important hyperparameters\n",
    "@dataclass(frozen=True)\n",
    "class ModelHyperparameters:\n",
    "    n_estimators: int = field(default=100, metadata={\"min\": 10, \"max\": 100})\n",
    "    max_depth: int = field(default=1, metadata={\"min\": 1, \"max\": 50})\n",
    "    min_samples_split: int = field(default=2, metadata={\"min\": 2, \"max\": 20})\n",
    "    min_samples_leaf: int = field(default=1, metadata={\"min\": 1, \"max\": 20})\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash(\n",
    "            (\n",
    "                self.n_estimators,\n",
    "                self.max_depth,\n",
    "                self.min_samples_split,\n",
    "                self.min_samples_leaf,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def validate(self) -> None:\n",
    "        for field_name, field_def in self.__dataclass_fields__.items():\n",
    "            value = getattr(self, field_name)\n",
    "            metadata = field_def.metadata\n",
    "            if \"min\" in metadata and value < metadata[\"min\"]:\n",
    "                raise ValueError(f\"{field_name} should be at least {metadata['min']}\")\n",
    "            if \"max\" in metadata and value > metadata[\"max\"]:\n",
    "                raise ValueError(f\"{field_name} should be at most {metadata['max']}\")\n",
    "\n",
    "\n",
    "# Define a function to create a ModelHyperparameters object with random values within the ranges\n",
    "def create_random_hyperparameters() -> ModelHyperparameters:\n",
    "    return ModelHyperparameters(\n",
    "        n_estimators=random.randint(10, 1000),\n",
    "        max_depth=random.randint(1, 50),\n",
    "        min_samples_split=random.randint(2, 20),\n",
    "        min_samples_leaf=random.randint(1, 20),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for loading and splitting the data\n",
    "def load_and_split_data_iris(\n",
    "    test_size: float = 0.5, random_state: int = 42\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    iris = load_iris()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def load_and_split_data_wine(\n",
    "    test_size: float = 0.5, random_state: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # Fetch the dataset\n",
    "    wine_quality = fetch_ucirepo(id=186)\n",
    "\n",
    "    # Extract features and targets\n",
    "    X = wine_quality.data.features.to_numpy()\n",
    "    y = wine_quality.data.targets.to_numpy().ravel()\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def load_and_split_data_wine_rebalanced(\n",
    "    test_size: float = 0.5, random_state: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    # Fetch the dataset\n",
    "    wine_quality = fetch_ucirepo(id=186)\n",
    "\n",
    "    # Extract features and targets\n",
    "    X = wine_quality.data.features.to_numpy()\n",
    "    y = wine_quality.data.targets.to_numpy().ravel()\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Apply SMOTE to rebalance the training data\n",
    "    smote = SMOTE(\n",
    "        sampling_strategy=\"auto\",\n",
    "        k_neighbors=min(5, len(np.unique(y_train)) - 1),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    try:\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    except ValueError as e:\n",
    "        # Fallback to reduce k_neighbors if not enough samples are available\n",
    "        smote = SMOTE(\n",
    "            sampling_strategy=\"auto\", k_neighbors=1, random_state=random_state\n",
    "        )\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_and_split_data_wine_rebalanced()\n",
    "\n",
    "\n",
    "# Define function to train the RandomForestClassifier\n",
    "def train_random_forest(\n",
    "    params: ModelHyperparameters, random_state: int = 42\n",
    ") -> RandomForestClassifier:\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params.n_estimators,\n",
    "        max_depth=params.max_depth,\n",
    "        min_samples_split=params.min_samples_split,\n",
    "        min_samples_leaf=params.min_samples_leaf,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "# Define function to evaluate the model\n",
    "def evaluate_model(clf: RandomForestClassifier) -> float:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    return f1_macro\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1064)\n",
    "def get_fitness(params: ModelHyperparameters) -> float:\n",
    "    model = train_random_forest(params, 42)\n",
    "    fitness = evaluate_model(model)\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation function for hyperparameters\n",
    "def mutate(param: ModelHyperparameters, mut_prob: float = 0.05) -> ModelHyperparameters:\n",
    "    def mutate_param(field_name: str, val: int, metadata: dict) -> int:\n",
    "        if random.random() < mut_prob:\n",
    "            min_val = metadata.get(\"min\", val)\n",
    "            max_val = metadata.get(\"max\", val)\n",
    "            return random.randint(min_val, max_val)\n",
    "        return val\n",
    "\n",
    "    return ModelHyperparameters(\n",
    "        n_estimators=mutate_param(\n",
    "            \"n_estimators\",\n",
    "            param.n_estimators,\n",
    "            ModelHyperparameters.__dataclass_fields__[\"n_estimators\"].metadata,\n",
    "        ),\n",
    "        max_depth=(\n",
    "            mutate_param(\n",
    "                \"max_depth\",\n",
    "                param.max_depth if param.max_depth is not None else 1,\n",
    "                ModelHyperparameters.__dataclass_fields__[\"max_depth\"].metadata,\n",
    "            )\n",
    "            if param.max_depth is not None\n",
    "            else None\n",
    "        ),\n",
    "        min_samples_split=mutate_param(\n",
    "            \"min_samples_split\",\n",
    "            param.min_samples_split,\n",
    "            ModelHyperparameters.__dataclass_fields__[\"min_samples_split\"].metadata,\n",
    "        ),\n",
    "        min_samples_leaf=mutate_param(\n",
    "            \"min_samples_leaf\",\n",
    "            param.min_samples_leaf,\n",
    "            ModelHyperparameters.__dataclass_fields__[\"min_samples_leaf\"].metadata,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "# Crossover function for two hyperparameter sets\n",
    "def crossover(\n",
    "    params1: ModelHyperparameters, params2: ModelHyperparameters, cross_prob: float\n",
    ") -> ModelHyperparameters:\n",
    "\n",
    "    if random.random() > cross_prob:\n",
    "        return random.choice([params1, params2])\n",
    "\n",
    "    return ModelHyperparameters(\n",
    "        n_estimators=random.choice([params1.n_estimators, params2.n_estimators]),\n",
    "        max_depth=random.choice([params1.max_depth, params2.max_depth]),\n",
    "        min_samples_split=random.choice(\n",
    "            [params1.min_samples_split, params2.min_samples_split]\n",
    "        ),\n",
    "        min_samples_leaf=random.choice(\n",
    "            [params1.min_samples_leaf, params2.min_samples_leaf]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    maxGen: int = 100,\n",
    "    popSize: int = 10,\n",
    "    tournSize: int = 2,\n",
    "    mutProb: float = 0.05,\n",
    "    crossProb: float = 0.8,\n",
    "):\n",
    "\n",
    "    fittest = (None, -1)\n",
    "    gen = 0\n",
    "\n",
    "    pop = [create_random_hyperparameters() for _ in range(popSize)]\n",
    "\n",
    "    while gen < maxGen:\n",
    "\n",
    "        pop.sort(key=lambda x: get_fitness(x), reverse=True)\n",
    "        bestSol = pop[0]\n",
    "        bestFit = get_fitness(bestSol)\n",
    "\n",
    "        if bestFit > fittest[1]:\n",
    "            fittest = bestSol, bestFit\n",
    "\n",
    "        print(f\"Generation {gen} - Best Solution: {pop[0]}\")\n",
    "        print(f\"Fitness: {get_fitness(pop[0])}\")\n",
    "        breadingPop = []\n",
    "\n",
    "        while len(breadingPop) < popSize / 2:\n",
    "\n",
    "            tournPool = random.choices(pop, k=tournSize)\n",
    "            tournPool.sort(key=lambda x: get_fitness(x), reverse=True)\n",
    "            breadingPop.append(tournPool[0])\n",
    "\n",
    "        pop = []\n",
    "\n",
    "        while len(pop) < popSize:\n",
    "\n",
    "            mom, dad = random.choices(breadingPop, k=2)\n",
    "            child = mutate(crossover(mom, dad, crossProb), mutProb)\n",
    "            pop.append(child)\n",
    "\n",
    "        gen += 1\n",
    "\n",
    "    return fittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
